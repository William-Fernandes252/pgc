\chapter{Fundamentação Teórica}\label{cap:fundamentacaoTeorica}

% \section*{Trabalhos Relacionados a Isto}
% \label{sec:primTrab}
% \addcontentsline{toc}{section}{Trabalhos Relacionados a Isto}

% \lipsum[34-36]

\textit{Machine Learning} é o processo de fazer com que computadores modifiquem, ou adaptem, as suas ações de modo que elas se tornem progressivamente mais eficazes segundo um conjunto de métricas~\cite{StephenMarsland2014}. É uma sub-área da Inteligência Artificial que foca na reprodução computacional do aprendizado, no sentido de desenvolver programas capazes de generalizar um problema: reconhecer que dentro de um determinado contexto (entrada), se uma decisão em particular (saída) foi a correta, então ela pode funcionar novamente, ou se ela foi equivocada, uma estratégia diferente deve ser elaborada.

Os métodos de utilizados para atingir esse comportamento podem ser divididos em aprendizado supervisionado e não-supervisionado. No aprendizado supervisionado, um conjunto de dados de treinamento é utilizado juntamente com as respostas esperadas (rótulos) é fornecido, e com isso um algoritmo generaliza o problema, se tornando capaz de prever a resposta correta para novas entradas. Quando essa resposta é categórica, diz-se que o algoritmo é de classificação, e quando é contínua chama-se regressão~\cite{SindhuMeena2020}. O aprendizado não-supervisionado, por sua vez, opera em dados não rotulados para identificar padrões~\cite{Dike2018}.

O escopo deste projeto concentra-se na tarefa de classificação binária aplicada a conjuntos de dados utilizados na avaliação de risco de crédito. Nesse contexto, é comum a ocorrência de desbalanceamento entre as classes, o que pode impactar negativamente o desempenho dos modelos preditivos~\cite{Namvar2018}. Assim, estratégias que considerem esse desbalanceamento tendem a produzir resultados mais robustos. Este capítulo, portanto, explora os principais conceitos e técnicas relacionados ao desenvolvimento de modelos de classificação em cenários com dados desbalanceados.

\section{Métricas de desempenho de classificadores}

A escolha das métricas de desempenho é determinante para uma avaliação precisa e confiável de um classificador~\cite{Gaudreault2021}. Os indicadores de performance utilizados hoje têm sua origem em variados domínios incluindo estatística (distância, similaridade binária etc.), processamento de sinais (\textit{area under the receiver operating characteristic curve}) AUC, recuperação de informação (\textit{precision}, \textit{recall}), medicina diagnóstica (sensibilidade, especificidade), reconhecimento estatístico de padrões (acurácia), entre outros~\cite{Canbek2023}. Quando se trata da avaliação de classificadores binários, as métricas utilizadas na literatura podem ser agrupadas segundo a sua interpretação do erro~\cite{Ferri2009}:  acurácia e \textit{F-score}, por exemplo, representam o erro de forma qualitativa utilizando proporções entre a contagem de erros e acertos, enquanto que média do erro absoluto e \textit{Brier Score} dão uma visão probabilística do erro, isto é, medem o desvio das previsões da sua probabilidade real.

Para o uso das métricas qualitativas, a contagem dos erros e acertos é representada com uma matriz \(M\), chamada de Matriz de confusão. Nesta matriz, cada elemento \(M_{ij}\) corresponde ao número de vezes com que uma instância da classe \(i\) foram identificados como pertencentes à classe \(j\).

Em problemas de classificação binária desbalanceada, a classe mais frequente é chamada de majoritária ou negativa, e a classe menos frequente é chamada de minoritária ou positiva~\cite{Seiffert2008,Batuwita2010}. Com base nisso, a matriz de confusão para esses casos pode ser vista na Tabela~\ref{tab:matriz-confusao}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{cc|cc|}
    \cline{3-4}
    \multicolumn{2}{c|}{\multirow{2}{*}{}}                   & \multicolumn{2}{c|}{\textbf{Real}}                                                                                \\ \cline{3-4}
    \multicolumn{2}{c|}{}                                    & \multicolumn{1}{c|}{\textbf{Negativa}} & \textbf{Positiva}                                                        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Predição}}} & \textbf{Negativa}                      & \multicolumn{1}{c|}{TN (verdadeiro negativo)} & FN (falso negativo)      \\ \cline{2-4}
    \multicolumn{1}{|c|}{}                                   & \textbf{Positiva}                      & \multicolumn{1}{c|}{FP (falso positivo)}      & TP (verdadeiro positivo) \\ \hline
  \end{tabular}
  \caption{Matriz de confusão binária.}
  \label{tab:matriz-confusao}
\end{table}

\section{Técnicas de re-amostragem}

Considerando a perda de desempenho que muitos algoritmos apresentam diante de dados desbalanceados, alguns métodos foram desenvolvidos para mitigar a discrepância entre as classes e evitar o surgimento de viés a favor da classe majoritária. Esse processo, conhecido de re-amostragem, altera o conjunto de dados adicionando ou removendo instâncias seguindo algum critério~\cite{Chakravarthy2019}. Essas abordagens são amplamente aplicadas devido a sua versatilidade: como envolvem apenas os dados, o seu uso independe de qualquer modelo específico ou contexto de classificação~\cite{Carvalho2025}. As técnicas de re-amostragem podem ser divididas em três tipos~\cite{Haixiang2017}:

\begin{itemize}
  \item sobre-amostragem, (ou \textit{oversampling}) consiste em criar novas instâncias da classe minoritária, reduzindo o grau de desbalanceamento do conjunto de dados;
  \item sub-amostragem (ou \textit{undersampling}), que cria novas amostras da classe minoritária~\cite{Mohammed2020};
  \item abordagem híbrida, que combina os dois tipos anteriores.
\end{itemize}

Dentre as técnicas mais simples — e ainda amplamente utilizadas — destacam-se as não heurísticas, como o \textit{Random Oversampling} (ROC), que gera amostras sintéticas, e o \textit{Random Undersampling}, que remove aleatoriamente instâncias do conjunto de dados durante o treinamento. No entanto, esses métodos não garantem uma melhoria de desempenho em todas as aplicações~\cite{Yang2024} e podem acarretar problemas, como \textit{overfitting} ou perda de informações relevantes~\cite{Fernndez2018}.

Partindo para o campo das técnicas heurísticas temos, por exemplo, o \textit{Tomek links}, um método de sub-amostragem que busca melhorar a performance de classificadores reduzindo ambiguidades em pontos de borda do conjunto de dados. Sejam \(S_{i}\) e \(S_{j}\) dois exemplos de classes distintas, e seja \(d_{ij}\) a distância Euclidiana entre eles. Um par \(S_{i}, S_{j}\) é considerado um \textit{Tomek link} se não existir nenhum \(S_{l}\) tal que \(d_{il} < d_{ij}\) ou \(d_{jl} < d_{ij}\)~\cite{Batista2004}. Para aplicar o \textit{Tomek links}, primeiro se calcula os vizinhos mais próximos de cada membro da classe minoritária. Em seguida, identificam-se os pares. Para cada par, o elemento da classe majoritária é eliminado. Esse processo pode ser repetido iterativamente para aumentar a separação entre as classes~\cite{Arichandrapandian2024}. Apesar de ter sido proposto inicialmente para problemas de classificação de rótulo único, ele já foi adaptado para lidar com múltiplas classes~\cite{Pereira2020}.

\textit{Synthetic minority oversampling} (SMOTE), é um método de sobre-amostragem que introduz uma abordagem baseada em interpolação para gerar novas instâncias da classe minoritária~\cite{Wei2025}. Ao invés de criar exemplos totalmente aleatórios, o SMOTE cria amostras sintéticas a partir da combinação de instâncias próximas, o que contribui para uma modelagem mais robusta e representativa da classe minoritária, além de melhorar a capacidade de generalização dos modelos preditivos. Inicialmente, o método agrupa as amostras positivas utilizando, por exemplo, o algoritmo \textit{k-Nearest Neighbors} (k-NN). Em seguida, para cada nova amostra a ser gerada, duas instâncias \(x_{1}\) e \(x_{2}\) pertencentes ao mesmo grupo são selecionadas, e a instância sintética é obtida por meio da interpolação \(x = x_{1} + \lambda \bigtimes (x_{1} - x_{2})\), onde \(\lambda\) é um número aleatório no intervalo \([0, 1]\). Essa técnica tem se mostrado eficaz na redução do viés de aprendizado causado pelo desbalanceamento, é amplamente utilizada em diferentes domínios de aplicação e inspirou diversos outros algoritmos de re-amostragem para lidar com desbalanceamento~\cite{Fernndez2018}.

Em bases de dados desbalanceadas, é comum que aglomerados da classe minoritária não sejam bem definidos devido a presença de elementos da classe majoritária. O contrário, onde instâncias negativas se encontram isoladas em uma parte do espaço amostral dominada por instâncias negativas, também é frequente na prática, inclusive com o uso de sobre-amostragem. O risco de \textit{over-fitting} aumenta em ambos os casos~\cite{Batista2004}.