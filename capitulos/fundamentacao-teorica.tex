\chapter{Fundamentação Teórica}\label{cap:fundamentacaoTeorica}

% \section*{Trabalhos Relacionados a Isto}
% \label{sec:primTrab}
% \addcontentsline{toc}{section}{Trabalhos Relacionados a Isto}

% \lipsum[34-36]

\textit{Machine Learning} é o processo de fazer com que computadores modifiquem, ou adaptem, as suas ações de modo que elas se tornem progressivamente mais eficazes segundo um conjunto de métricas~\cite{StephenMarsland2014}. É uma sub-área da Inteligência Artificial que foca na reprodução computacional do aprendizado, no sentido de desenvolver programas capazes de generalizar um problema: reconhecer que dentro de um determinado contexto (entrada), se uma decisão em particular (saída) foi a correta, então ela pode funcionar novamente, ou se ela foi equivocada, uma estratégia diferente deve ser elaborada.

Os métodos de utilizados para atingir esse comportamento podem ser divididos em aprendizado supervisionado e não-supervisionado. No aprendizado supervisionado, um conjunto de dados de treinamento é utilizado juntamente com as respostas esperadas (rótulos) é fornecido, e com isso um algoritmo generaliza o problema, se tornando capaz de prever a resposta correta para novas entradas. Quando essa resposta é categórica, diz-se que o algoritmo é de classificação, e quando é contínua chama-se regressão~\cite{SindhuMeena2020}. O aprendizado não-supervisionado, por sua vez, opera em dados não rotulados para identificar padrões~\cite{Dike2018}.

O escopo deste projeto concentra-se na tarefa de classificação binária aplicada a conjuntos de dados utilizados na avaliação de risco de crédito. Nesse contexto, é comum a ocorrência de desbalanceamento entre as classes, o que pode impactar negativamente o desempenho dos modelos preditivos~\cite{Namvar2018}. Assim, estratégias que considerem esse desbalanceamento tendem a produzir resultados mais robustos. Este capítulo, portanto, explora os principais conceitos e técnicas relacionados ao desenvolvimento de modelos de classificação em cenários com dados desbalanceados.

\section{Métricas de desempenho de classificadores}

A escolha das métricas de desempenho é determinante para uma avaliação precisa e confiável de um classificador~\cite{Gaudreault2021}. Os indicadores de performance utilizados hoje têm sua origem em variados domínios incluindo estatística (distância, similaridade binária etc.), processamento de sinais (\textit{area under the receiver operating characteristic curve}) AUC, recuperação de informação (\textit{precision}, \textit{recall}), medicina diagnóstica (sensibilidade, especificidade), reconhecimento estatístico de padrões (acurácia), entre outros~\cite{Canbek2023}. Quando se trata da avaliação de classificadores binários, as métricas utilizadas na literatura podem ser agrupadas segundo a sua interpretação do erro~\cite{Ferri2009}:  acurácia e \textit{F-score}, por exemplo, representam o erro de forma qualitativa utilizando proporções entre a contagem de erros e acertos, enquanto que média do erro absoluto e \textit{Brier Score} dão uma visão probabilística do erro, isto é, medem o desvio das previsões da sua probabilidade real.

Para o uso das métricas qualitativas, a contagem dos erros e acertos é representada com uma matriz \(M\), chamada de Matriz de confusão. Nesta matriz, cada elemento \(M_{ij}\) corresponde ao número de vezes com que uma instância da classe \(i\) foram identificados como pertencentes à classe \(j\).

Em problemas de classificação binária desbalanceada, a classe mais frequente é chamada de majoritária ou negativa, e a classe menos frequente é chamada de minoritária ou positiva~\cite{Seiffert2008,Batuwita2010}. Com base nisso, a matriz de confusão para esses casos pode ser vista na Tabela~\ref{tab:matriz-confusao}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{cc|cc|}
    \cline{3-4}
    \multicolumn{2}{c|}{\multirow{2}{*}{}}                   & \multicolumn{2}{c|}{\textbf{Real}}                                                                                \\ \cline{3-4}
    \multicolumn{2}{c|}{}                                    & \multicolumn{1}{c|}{\textbf{Negativa}} & \textbf{Positiva}                                                        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Predição}}} & \textbf{Negativa}                      & \multicolumn{1}{c|}{TN (verdadeiro negativo)} & FN (falso negativo)      \\ \cline{2-4}
    \multicolumn{1}{|c|}{}                                   & \textbf{Positiva}                      & \multicolumn{1}{c|}{FP (falso positivo)}      & TP (verdadeiro positivo) \\ \hline
  \end{tabular}
  \caption{Matriz de confusão binária.}
  \label{tab:matriz-confusao}
\end{table}

\section{Técnicas de re-amostragem}

Considerando a perda de desempenho que muitos algoritmos apresentam diante de dados desbalanceados, alguns métodos foram desenvolvidos para mitigar a discrepância entre as classes e evitar o surgimento de viés a favor da classe majoritária. Esse processo, conhecido de re-amostragem, altera o conjunto de dados adicionando ou removendo instâncias seguindo algum critério~\cite{Chakravarthy2019}. Essas abordagens são amplamente aplicadas devido a sua versatilidade: como envolvem apenas os dados, o seu uso independe de qualquer modelo específico ou contexto de classificação~\cite{Carvalho2025}. As técnicas de re-amostragem podem ser divididas em três tipos~\cite{Haixiang2017}:

\begin{itemize}
  \item sobre-amostragem, (ou \textit{oversampling}) consiste em criar novas instâncias da classe minoritária, reduzindo o grau de desbalanceamento do conjunto de dados;
  \item sub-amostragem (ou \textit{undersampling}), que cria novas amostras da classe minoritária~\cite{Mohammed2020};
  \item abordagem híbrida, que combina os dois tipos anteriores.
\end{itemize}

Dentre as técnicas mais simples — e ainda amplamente utilizadas — destacam-se as não heurísticas, como o \textit{Random Oversampling} (ROC), que gera amostras sintéticas, e o \textit{Random Undersampling}, que remove aleatoriamente instâncias do conjunto de dados durante o treinamento. No entanto, esses métodos não garantem uma melhoria de desempenho em todas as aplicações~\cite{Yang2024} e podem acarretar problemas, como \textit{overfitting} ou perda de informações relevantes~\cite{Fernndez2018}.

Partindo para o campo das técnicas heurísticas temos, por exemplo, o \textit{Tomek links}, um método de sub-amostragem que busca melhorar a performance de classificadores reduzindo ambiguidades em pontos de borda do conjunto de dados. Sejam \(S_{i}\) e \(S_{j}\) dois exemplos de classes distintas, e seja \(d_{ij}\) a distância Euclidiana entre eles. Um par \(S_{i}, S_{j}\) é considerado um \textit{Tomek link} se não existir nenhum \(S_{l}\) tal que \(d_{il} < d_{ij}\) ou \(d_{jl} < d_{ij}\)~\cite{Batista2004}. Para aplicar o \textit{Tomek links}, primeiro se calcula os vizinhos mais próximos de cada membro da classe minoritária. Em seguida, identificam-se os pares. Para cada par, o elemento da classe majoritária é eliminado. Esse processo pode ser repetido iterativamente para aumentar a separação entre as classes~\cite{Arichandrapandian2024}. Apesar de ter sido proposto inicialmente para problemas de classificação de rótulo único, ele já foi adaptado para lidar com múltiplas classes~\cite{Pereira2020}.

\textit{Synthetic minority oversampling} (SMOTE), é um método de sobre-amostragem que introduz uma abordagem baseada em interpolação para gerar novas instâncias da classe minoritária~\cite{Wei2025}. Ao invés de criar exemplos totalmente aleatórios, o SMOTE cria amostras sintéticas a partir da combinação de instâncias próximas, o que contribui para uma modelagem mais robusta e representativa da classe minoritária, além de melhorar a capacidade de generalização dos modelos preditivos. Inicialmente, o método agrupa as amostras positivas utilizando, por exemplo, o algoritmo \textit{k-Nearest Neighbors} (k-NN). Em seguida, para cada nova amostra a ser gerada, duas instâncias \(x_{1}\) e \(x_{2}\) pertencentes ao mesmo grupo são selecionadas, e a instância sintética é obtida por meio da interpolação \(x = x_{1} + \lambda \bigtimes (x_{1} - x_{2})\), onde \(\lambda\) é um número aleatório no intervalo \([0, 1]\). Essa técnica tem se mostrado eficaz na redução do viés de aprendizado causado pelo desbalanceamento, é amplamente utilizada em diferentes domínios de aplicação e inspirou diversos outros algoritmos de re-amostragem para lidar com desbalanceamento~\cite{Fernndez2018}. \textit{Adaptative synthetic} (ADASYN) \textit{sampling} é uma alternativa ao SMOTE para sobre-amostragem. Nessa abordagem, a distribuição das instâncias negativas é utilizada para se definir o número ideal de amostras sintéticas a serem geradas para cada amostra da classe minoritária com o objetivo de reduzir o viés introduzido pelo desbalanceamento, e ao mesmo tempo otimizar a precisão das decisões~\cite{He2008}.

Em bases de dados desbalanceadas, é comum que aglomerados da classe minoritária não sejam bem definidos devido a presença de elementos da classe majoritária. O contrário, onde instâncias negativas se encontram isoladas em uma parte do espaço amostral dominada por instâncias negativas, também é frequente na prática, inclusive após o uso de sobre-amostragem. O risco de \textit{over-fitting} aumenta em ambos os casos~\cite{Batista2004}. Para se atingir uma separação mais bem-definida entre as classes, uma combinação de técnicas de sobre-amostragem e sub-amostragem podem ser aplicadas, com a primeira servindo para aumentar a representatividade da classe minoritária, e a segunda para limpar o conjunto de dados, removendo redundâncias e reforçando fronteiras~\cite{Pereira2020}. SMOTE-Tomek e SMOTE-ENN são exemplos de técnicas híbridas, que adicionam uma fase de pós-processamento ao SMOTE, utilizando respectivamente \textit{Tomek links} e \textit{Edited Nearest Neighbor} (ENN).
\section{Aprendizado sensível ao custo}

O aprendizado sensível a custos é um conjunto de algoritmos que introduz pesos diferenciados para os erros em diferentes estágios da fase de treinamento~\cite{FernndezCs2018}. Os custos podem ser atribuídos às \textit{features}, quando o objetivo é otimizar a performance da classificação utilizando um subconjunto específico de \textit{features}~\cite{Zhou2016}, ou às classes em problemas de classificação, onde falhas na identificação de instâncias da classe de interesse são penalizadas de forma mais severa durante o processo de treinamento.

No contexto de desbalanceamento, o aprendizado sensível a custos é uma abordagem a nível de algoritmo~\cite{Krawczyk2016}. Ela se baseia no fato de que a função de perda padrão, que atribui 0 para acertos e 1 para erros, é problemática em distribuições desequilibradas, pois é facilmente minimizada concentrando-se apenas na classe majoritária, negligenciando a classe minoritária ou até mesmo ignorando ela por completo, a depender do grau de desbalanceamento~\cite{Landgrebe2004}. Nessa abordagem, esse problema é resolvido adaptando-se a função de perda usando, por exemplo, uma matriz de custos \(C\), que associa um peso específico para cada \(C_{ij}\) possível. Com penalidades maiores para erros envolvendo a classe minoritária, o processo de treinamento dá uma enfase maior nessas instâncias.

Naturalmente, a efetividade do aprendizado sensível a custos depende fortemente da matriz de custos fornecida~\cite{FernndezCs2018}. Geralmente, ela é definida com o acompanhamento de um especialista no problema estudado. Sahin, Bulkan e Dulman (\citeyear{Sahin2013}), por exemplo, elaboraram uma matriz de custos para análise de risco de crédito após entrevistarem colaboradores de uma instituição financeira. Quando não é possível consultar um especialista, alguns trabalhos utilizam como alternativa estratégias analíticas para a definição de \(C\). Bahnsen, Djamila e Ottersten (\citeyear{Bahnsen2015}) desenvolveram um método para determinar o custo de cada exemplo durante a fase de treinamento.

Os algoritmos de aprendizado sensível ao custo podem ser categorizados entre aprendizagem direta, onde algoritmos existentes são adaptados para o uso de uma função de custo específica, e meta-aprendizado, que consiste em incorporar modificar a entrada (dados de teste) ou saída de um classificador~\cite{FernndezCs2018}. \textit{Cost-sensitive tree} é um exemplo de algoritmo da primeira categoria, que permite a introdução de custos, tanto das \textit{features} quanto de classificações incorretas, a uma árvore de decisão~\cite{Ling2006}.

Proposto por Domingos (\citeyear{Domingos1999}), \textit{MetaCost} é um método genérico de meta-aprendizado que permite adicionar um procedimento de minimização de custo a qualquer classificador, independentemente do formato de sua saída. A flexibilidade e a simplicidade da sua implementação, faz com o algoritmo se destaque entre os demais~\cite[text]{FernndezCs2018, Wang2018}. O processo de treinamento utilizando o \textit{MetaCost} é divido em duas partes. Primeiro, \(m\) subconjuntos são criados a partir do conjunto de dados de teste original, cada qual usado para treinar um classificador base (por exemplo, regressão logística, \textit{decision tree} etc.). Cada classificador gera probabilidades de classe para cada instância, ou apenas o rótulo quando ele não suporta probabilidades~\cite{Araf2024}. Em seguida, para cada exemplo original, é calculada a média das previsões dos classificadores base (ou votação por maioria), que é usada para calcular o custo esperado de classificá-lo em cada classe, multiplicando pela matriz de custos. O rótulo da instância é então redefinido para a classe minimiza o custo. Com o conjunto de treinamento re-rotulado, um classificador final é então treinado com os exemplos atualizados. Esse classificador final é sensível ao custo e tem um desempenho superior aos classificadores treinados com os dados originais~\cite{Chen2021}.

\section{Trabalhos Relacionados}

Ao longo dos anos, com o avanço acelerado das técnicas de modelagem, da capacidade computacional e dos softwares que sustentam aplicações de inteligência artificial, o uso de modelos baseados em \textit{machine learning} para análise de risco de crédito tem se tornado cada vez mais prevalente em relação às abordagens puramente estatísticas. Adicionalmente, o surgimento de novas modalidades de crédito, como o empréstimo entre pessoas (\textit{peer-to-peer} ou P2P), aliado ao uso de estratégias de diversificação cada vez mais sofisticadas, demanda modelos mais robustos, confiáveis e capazes de lidar com diferentes características dos dados.

Dado que a inadimplência é geralmente um evento raro, o desequilíbrio entre classes continua sendo um dos principais desafios na modelagem preditiva. Dessa forma, a experimentação e comparação de técnicas que lidam com o desbalanceamento ainda são de grande relevância. Esta seção apresenta uma revisão de estudos recentes que abordam a classificação de risco de crédito em cenários de forte desbalanceamento entre classes.

Namvar \textit{et al.}~(\citeyear{Namvar2018}) exploram esse problema no contexto de empréstimos P2P, comparando diferentes técnicas de reamostragem quanto à sua eficácia na melhoria do desempenho dos classificadores, com foco principal na métrica \textit{G-mean}. Os autores destacam o uso de \textit{Random Forest} combinado com \textit{Random Undersampling} (RUS) como uma solução promissora para a previsão de inadimplência. Apesar da redução na acurácia média, os modelos ajustados para o desbalanceamento mostraram menor viés em relação à classe majoritária, tornando-se mais adequados para o objetivo da tarefa.

Wang, Kou e Peng~(\citeyear{Namvar2018}), utilizando o mesmo conjunto de dados, avaliaram o impacto do aprendizado sensível ao custo por meio da técnica \textit{MetaCost}. Embora com foco em uma abordagem distinta, os resultados convergem com os de Namvar \textit{et al.}, reforçando que o tratamento do desbalanceamento durante o treinamento contribui para a redução do viés dos modelos, promovendo classificações mais equilibradas.

No âmbito do crédito corporativo, o problema do desbalanceamento se intensifica devido à maior complexidade dos dados e à necessidade de considerar um volume substancial de variáveis. Wei~(\citeyear{Wei2025}) propõe uma extensão do SMOTE, adaptada a esse cenário, na qual são atribuídos pesos diferenciados às \textit{features} mais relevantes para avaliação de risco em setores específicos. Apesar dos resultados promissores obtidos em múltiplos conjuntos de dados, o autor destaca que ainda existem relações complexas e intrínsecas entre as variáveis — como a dinâmica competitiva entre empresas e particularidades setoriais — que as abordagens atuais não conseguem generalizar adequadamente. Como alternativa, o uso de técnicas de \textit{Deep Learning} é apontado como uma possível direção para superar essas limitações.

Diante desse panorama, este trabalho tem como objetivo apresentar uma comparação sistemática entre as principais abordagens utilizadas para lidar com o desbalanceamento entre classes no contexto da análise de risco de crédito. Serão avaliadas diferentes técnicas em conjuntos de dados provenientes de distintas modalidades de empréstimo, com o intuito de identificar quais métodos apresentam melhor desempenho conforme métricas adequadas à classificação de risco.
