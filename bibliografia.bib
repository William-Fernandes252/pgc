%% PPGCC - CCN - UFPI

%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/
%% Exemplo de arquivo .bib a ser utilizado para gerar a Biliografia

%% Quando for no Google Scholar, clique em bibtex na citação e copie o código pra colar aqui





@misc{abntex2-wiki-como-customizar,
  author        = {abnTeX2},
  date-added    = {2013-03-23 21:39:21 +0000},
  date-modified = {2013-03-23 21:44:20 +0000},
  howpublished  = {Wiki do abnTeX2},
  keywords      = {wiki},
  title         = {Como customizar o abnTeX2},
  url           = {https://code.google.com/p/abntex2/wiki/ComoCustomizar},
  urlaccessdate = {23 mar. 2013},
  year          = {2013},
  bdsk-url-1    = {https://code.google.com/p/abntex2/wiki/ComoCustomizar}
}

@manual{abntex2cite,
  annote        = {Este documento {\'e} derivado do \cite{abnt-bibtex-doc}},
  author        = {abnTeX2 and Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-09 10:37:45 +0000},
  date-modified = {2013-04-05 10:47:36 +0000},
  organization  = {Equipe abnTeX2},
  title         = {O pacote abntex2cite: Estilos bibliogr{\'a}ficos compat{\'\i}veis com a ABNT NBR 6023},
  url           = {http://abntex2.googlecode.com/},
  year          = {2013},
  bdsk-url-1    = {http://code.google.com/p/abntex2/}
}

@manual{abntex2cite-alf,
  annote        = {Este documento {\'e} derivado do \cite{abnt-bibtex-alf-doc}},
  author        = {abnTeX2 and Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-09 10:37:45 +0000},
  date-modified = {2013-04-05 11:03:05 +0000},
  organization  = {Equipe abnTeX2},
  title         = {O pacote abntex2cite: t{\'o}picos espec{\'\i}ficos da ABNT NBR 10520:2002 e o estilo bibliogr{\'a}fico alfab{\'e}tico (sistema autor-data)},
  url           = {http://abntex2.googlecode.com/},
  year          = {2013},
  bdsk-url-1    = {http://code.google.com/p/abntex2/}
}

@manual{abntex2classe,
  author        = {abnTeX2 and Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-09 10:37:38 +0000},
  date-modified = {2013-04-05 11:03:48 +0000},
  organization  = {Equipe abnTeX2},
  title         = {A classe abntex2: Modelo can{\^o}nico de trabalhos acad{\^e}micos brasileiros compat{\'\i}vel com as normas ABNT NBR 14724:2011, ABNT NBR 6024:2012 e outras},
  url           = {http://abntex2.googlecode.com/},
  year          = {2013},
  bdsk-url-1    = {http://code.google.com/p/abntex2/}
}

@manual{abntex2modelo,
  annote        = {Este documento {\'e} derivado do \cite{abnt-bibtex-doc}},
  author        = {abnTeX2},
  date-added    = {2013-01-12 22:55:32 +0000},
  date-modified = {2013-02-04 12:05:54 +0000},
  organization  = {Equipe abnTeX2},
  title         = {Modelo Can{\^o}nico de Trabalho Acad{\^e}mico com abnTeX2},
  url           = {http://abntex2.googlecode.com/},
  year          = {2013},
  bdsk-url-1    = {http://code.google.com/p/abntex2/}
}

@manual{abntex2modelo-artigo,
  annote        = {Este documento {\'e} derivado do \cite{abnt-bibtex-doc}},
  author        = {abnTeX2},
  date-added    = {2013-01-15 00:10:35 +0000},
  date-modified = {2013-02-04 12:05:47 +0000},
  organization  = {Equipe abnTeX2},
  title         = {Modelo Can{\^o}nico de Artigo Cient{\'\i}fico com abnTeX2},
  url           = {http://abntex2.googlecode.com/},
  year          = {2013},
  bdsk-url-1    = {http://code.google.com/p/abntex2/}
}

@manual{abntex2modelo-relatorio,
  annote        = {Este documento {\'e} derivado do \cite{abnt-bibtex-doc}},
  author        = {abnTeX2},
  date-added    = {2013-01-15 00:05:34 +0000},
  date-modified = {2013-02-04 12:05:50 +0000},
  organization  = {Equipe abnTeX2},
  title         = {Modelo Can{\^o}nico de Relat{\'o}rio T{\'e}cnico e/ou Cient{\'\i}fico com abnTeX2},
  url           = {http://abntex2.googlecode.com/},
  year          = {2013},
  bdsk-url-1    = {http://code.google.com/p/abntex2/}
}

@mastersthesis{araujo2012,
  address       = {Bras{\'\i}lia},
  author        = {Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-09 11:04:42 +0000},
  date-modified = {2013-01-09 11:04:42 +0000},
  month         = {mar.},
  school        = {Universidade de Bras{\'\i}lia},
  subtitle      = {uma perspectiva de {A}rquitetura da {I}nforma{\c c}{\~a}o da {E}scola de {B}ras{\'\i}lia},
  title         = {Configura{\c c}{\~a}o},
  year          = {2012}
}

@manual{babel,
  author        = {Johannes Braams},
  date-added    = {2013-02-17 13:37:14 +0000},
  date-modified = {2013-02-17 13:38:38 +0000},
  month         = {Apr.},
  title         = {Babel, a multilingual package for use with LATEX's standard document classes},
  url           = {http://mirrors.ctan.org/info/babel/babel.pdf},
  urlaccessdate = {17 fev. 2013},
  year          = {2008},
  bdsk-url-1    = {http://mirrors.ctan.org/info/babel/babel.pdf}
}

@incollection{bates2010,
  address       = {New York},
  author        = {Marcia J. Bates},
  booktitle     = {Encyclopedia of Library and Information Sciences},
  date-added    = {2012-04-23 11:34:29 +0000},
  date-modified = {2012-04-23 11:34:29 +0000},
  edition       = {3rd},
  editor        = {Marcia J. Bates and Mary Niles Maack},
  pages         = {2347-2360},
  publisher     = {CRC Press},
  title         = {Information},
  url           = {http://pages.gseis.ucla.edu/faculty/bates/articles/information.html},
  urlaccessdate = {24 out. 2011},
  volume        = {3},
  year          = {2010},
  bdsk-url-1    = {http://pages.gseis.ucla.edu/faculty/bates/articles/information.html}
}

@book{dewey1980,
  address       = {New York, NY, USA},
  author        = {John Dewey},
  date-added    = {2012-04-23 11:34:16 +0000},
  date-modified = {2012-04-23 11:34:16 +0000},
  publisher     = {Perigee Books},
  title         = {Art as Experience},
  year          = {1980}
}

@book{doxiadis1965,
  author        = {Constantinos A. Doxiadis},
  date-added    = {2012-04-23 11:34:20 +0000},
  date-modified = {2012-04-23 11:34:20 +0000},
  publisher     = {Ceira - Coimbra},
  title         = {Arquitetura em Transi{\c c}{\~a}o},
  year          = {1965}
}

@manual{EIA649B,
  address       = {EUA},
  date-added    = {2012-04-23 11:34:59 +0000},
  date-modified = {2012-04-23 11:34:59 +0000},
  keywords      = {norma},
  month         = {June},
  organization  = {TechAmerica},
  title         = {ANSI/EIA 649-B: Configuration Management Standard},
  year          = {2011}
}

@inbook{guarino1995,
  address       = {Vienna},
  author        = {Nicola Guarino},
  booktitle     = {Philosophy and the Cognitive Science},
  date-added    = {2012-04-23 11:34:29 +0000},
  date-modified = {2012-04-23 11:34:29 +0000},
  editor        = {R. Casati and B. Smith and G. White},
  month         = {Sept.},
  pages         = {443-456},
  publisher     = {Holder-Pivhler-Tempsky},
  title         = {The Ontological Level},
  url           = {http://wiki.loa-cnr.it/Papers/OntLev.pdf},
  urlaccessdate = {2 jan. 2012},
  year          = {1995},
  bdsk-url-1    = {http://wiki.loa-cnr.it/Papers/OntLev.pdf}
}

@phdthesis{guizzardi2005,
  address       = {Enschede, The Netherlands},
  author        = {Giancarlo Guizzardi},
  date-added    = {2012-04-23 11:35:28 +0000},
  date-modified = {2012-04-23 11:35:28 +0000},
  school        = {Centre for Telematics and Information Technology, University of Twente},
  title         = {Ontological Foundations for Structural Conceptual Models},
  url           = {http://www.loa.istc.cnr.it/Guizzardi/SELMAS-CR.pdf},
  urlaccessdate = {3 jul. 2011},
  year          = {2005},
  bdsk-url-1    = {http://www.loa.istc.cnr.it/Guizzardi/SELMAS-CR.pdf}
}

@book{ibge1993,
  address       = {Rio de Janeiro},
  author        = {IBGE},
  date-added    = {2013-08-21 13:56:10 +0000},
  date-modified = {2013-08-21 13:56:10 +0000},
  edition       = {3},
  organization  = {http://biblioteca.ibge.gov.br/visualizacao/livros/liv23907.pdf},
  publisher     = {Centro de Documenta{\c c}{\~a}o e Dissemina{\c c}{\~a}o de Informa{\c c}{\~o}es. Funda{\c c}{\~a}o Intituto Brasileiro de Geografia e Estat{\'\i}stica},
  title         = {Normas de apresenta{\c c}{\~a}o tabular},
  urlaccessdate = {21 ago 2013},
  year          = {1993}
}

@mastersthesis{macedo2005,
  author        = {Fl{\'a}via L. Macedo},
  date-added    = {2012-04-23 11:35:13 +0000},
  date-modified = {2012-04-23 11:35:13 +0000},
  keywords      = {arquitetura da informa{\c c}{\~a}o},
  school        = {Universidade de Bras{\'\i}lia},
  title         = {Arquitetura da Informa{\c c}{\~a}o: aspectos espistemol{\'o}gicos, cient{\'\i}ficos e pr{\'a}ticos.},
  type          = {Disserta{\c c}{\~a}o de Mestrado},
  year          = {2005}
}

@inproceedings{masolo2010,
  author        = {Claudio Masolo},
  booktitle     = {Proceedings of the Twelfth International Conference on the Principles of Knowledge Representation and Reasoning (KR 2010)},
  date-added    = {2012-04-23 11:34:38 +0000},
  date-modified = {2012-04-23 11:34:38 +0000},
  editor        = {Lin, F. and Sattler, U.},
  pages         = {258-268},
  publisher     = {AAAI Press},
  title         = {Understanding Ontological Levels},
  url           = {http://wiki.loa-cnr.it/Papers/kr10v0.7.pdf},
  urlaccessdate = {2 jan. 2012},
  year          = {2010},
  bdsk-url-1    = {http://wiki.loa-cnr.it/Papers/kr10v0.7.pdf}
}

@manual{memoir,
  address       = {Normandy Park, WA},
  author        = {Peter Wilson and Lars Madsen},
  date-added    = {2013-01-09 10:37:50 +0000},
  date-modified = {2013-03-21 13:23:25 +0000},
  organization  = {The Herries Press},
  title         = {The Memoir Class for Configurable Typesetting - User Guide},
  url           = {http://mirrors.ctan.org/macros/latex/contrib/memoir/memman.pdf},
  urlaccessdate = {19 dez. 2012},
  year          = {2010},
  bdsk-url-1    = {http://ctan.tche.br/macros/latex/contrib/memoir/memman.pdf}
}

@manual{NBR10520:2002,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 21:43:38 +0000},
  date-modified = {2013-01-12 22:17:20 +0000},
  month         = {ago.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 7,
  subtitle      = {Informa{\c c}\~ao e documenta{\c c}\~ao --- Apresenta{\c c}\~ao de cita{\c c}\~oes em documentos},
  title         = {{NBR} 10520},
  year          = 2002
}

@manual{NBR14724:2001,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 20:34:08 +0000},
  date-modified = {2012-12-15 20:34:08 +0000},
  month         = {jul.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 6,
  subtitle      = {Informa{\c c}\~ao e documenta{\c c}\~ao --- trabalhos acad\^emicos --- apresenta{\c c}\~ao},
  title         = {{NBR} 14724},
  year          = 2001
}

@manual{NBR14724:2002,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 20:34:17 +0000},
  date-modified = {2012-12-15 20:34:17 +0000},
  month         = {ago.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 6,
  subtitle      = {Informa{\c c}\~ao e documenta{\c c}\~ao --- trabalhos acad\^emicos --- apresenta{\c c}\~ao},
  title         = {{NBR} 14724},
  year          = 2002
}

@manual{NBR14724:2005,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 20:34:08 +0000},
  date-modified = {2012-12-15 20:35:25 +0000},
  month         = {dez.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 9,
  subtitle      = {Informa{\c c}\~ao e documenta{\c c}\~ao --- trabalhos acad\^emicos --- apresenta{\c c}\~ao},
  title         = {{NBR} 14724},
  year          = 2005
}

@manual{NBR14724:2011,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 20:34:08 +0000},
  date-modified = {2012-12-15 20:35:25 +0000},
  month         = {mar.},
  note          = {Substitui a Ref.~\citeonline{NBR14724:2005}},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 15,
  subtitle      = {Informa{\c c}\~ao e documenta{\c c}\~ao --- trabalhos acad\^emicos --- apresenta{\c c}\~ao},
  title         = {{NBR} 14724},
  year          = 2011
}

@manual{NBR6024:2012,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 21:24:06 +0000},
  date-modified = {2012-12-15 21:24:28 +0000},
  month         = {fev.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 4,
  subtitle      = {Numera{\c c}\~ao progressiva das se{\c c}\~oes de um documento},
  title         = {{NBR} 6024},
  year          = 2012
}

@manual{NBR6028:2003,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 21:02:12 +0000},
  date-modified = {2012-12-15 21:02:50 +0000},
  month         = {nov.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 2,
  subtitle      = {Resumo - Apresenta{\c c}{\~a}o},
  title         = {{NBR} 6028},
  year          = 2003
}

@manual{talbot2012,
  author        = {Nicola L.C. Talbot},
  date-added    = {2013-03-11 12:06:04 +0000},
  date-modified = {2013-03-11 12:06:56 +0000},
  month         = {Nov.},
  title         = {User Manual for glossaries.sty},
  url           = {http://mirrors.ctan.org/macros/latex/contrib/glossaries/glossaries-user.pdf},
  urlaccessdate = {11 mar. 2013},
  year          = {2012},
  bdsk-url-1    = {http://mirrors.ctan.org/macros/latex/contrib/glossaries/glossaries-user.pdf}
}

@article{van86,
  author  = {{van}, Gigch, John P. and Leo L. Pipino},
  journal = {Future Computing Systems},
  number  = {1},
  pages   = {71-97},
  title   = {In search for a paradigm for the discipline of information systems},
  volume  = {1},
  year    = {1986}
}

@techreport{StephenMarsland2014,
  author = {Stephen Marsland},
  city   = {New York},
  doi    = {10.1201/b17476},
  isbn   = {9780429102509},
  month  = {10},
  pages  = {4-5},
  title  = {Machine Learning - An Algorithmic Perspective},
  year   = {2014}
}

@book{SindhuMeena2020,
  abstract  = {High dimensionality would be one of the major challenges faced by people working in research with big data as a high dimensionality that happens, while a dataset comprises of a big number of features. For resolving this issue, often researchers make use of a feature selection step for identification and removal of irrelevant features and repetitive features. Acceleration Artificial Bee Colony-Artificial Neural Network (AABC-ANN) has been introduced in the preceding research for handling the feature selection process over the big data. Computational complexity and inaccuracy of dataset remain as a problem for these methods. Enhanced Particle Swarm Optimization with Genetic Algorithm – Modified Artificial Neural Network (EPSOGA–MANN) is described in the proposed methodology for avoiding the above-mentioned issues. Modules including preprocessing, feature selection, and classification have been included in this research process. Fuzzy C Means (FCM) denotes the clustering algorithm which is used to handle the noise information efficiently in preprocessing. Feature selection process is carried out by means of EPSOGA algorithm optimally in this research. More important and relevant features are selected by EPSOGA optimization algorithm and as a result more accurate classification results are achieved in this work for huge volume of dataset. Input, hidden, and output layers are the three layers of MANN. It is introduced for improving the time complexity by means of neurons. The performance evaluation of the research method is conducted in the Matlab simulation environment.},
  author    = {K., Suriya, S. Sindhu Meena},
  doi       = {10.1007/978-3-030-24051-6},
  journal   = {Proceedings of International Conference on Artificial Intelligence, Smart Grid and Smart City Applications},
  month     = {3},
  publisher = {Springer International Publishing},
  title     = {Proceedings of International Conference on Artificial Intelligence, Smart Grid and Smart City Applications},
  year      = {2020}
}

@article{Dike2018,
  abstract  = {Artificial neural networks (ANN) have been applied effectively in numerous fields for the aim of prediction, knowledge discovery, classification, time series analysis, modeling, etc. ANN training can be assorted into Supervised learning, Reinforcement learning and Unsupervised learning. There are some limitations using supervised learning. These limitations can be overcome by using unsupervised learning technique. This gives us motivation to write a review on unsupervised learning based on ANN. One main problem associated with unsupervised learning is how to find the hidden structures in unlabeled data. This paper reviews on the training/learning of unsupervised learning based on artificial neural network. It provides a description of the methods of selecting and fixing a number of hidden nodes in an unsupervised learning environment based on ANN. Moreover, the status, benefits and challenges of unsupervised learning are also summarized.},
  author    = {Happiness Ugochi Dike and Yimin Zhou and Kranthi Kumar Deveerasetty and Qingtian Wu},
  doi       = {10.1109/CBS.2018.8612259},
  isbn      = {9781538673553},
  journal   = {2018 IEEE International Conference on Cyborg and Bionic Systems, CBS 2018},
  keywords  = {Artificial Neural Network,Hidden nodes,Training,Unsupervised learning},
  month     = {7},
  pages     = {322-327},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {Unsupervised Learning Based On Artificial Neural Network: A Review},
  year      = {2018}
}

@article{Gaudreault2021,
  abstract  = {Numerous machine learning applications involve dealing with imbalanced domains, where the learning focus is on the least frequent classes. This imbalance introduces new challenges for both the performance assessment of these models and their predictive modeling. While several performance metrics have been established as baselines in balanced domains, some cannot be applied to the imbalanced case since the use of the majority class in the metric could lead to a misleading evaluation of performance. Other metrics, such as the area under the precision-recall curve, have been demonstrated to be more appropriate for imbalance domains due to their focus on class-specific performance. There are, however, many proposed implementations for this particular metric, which could potentially lead to different conclusions depending on the one used. In this research, we carry out an experimental study to better understand these issues and aim at providing a set of recommendations by studying the impact of using different metrics and different implementations of the same metric under multiple imbalance settings.},
  author    = {Jean Gabriel Gaudreault and Paula Branco and João Gama},
  doi       = {10.1007/978-3-030-88942-5_6/TABLES/6},
  isbn      = {9783030889418},
  issn      = {16113349},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords  = {Imbalanced domains,Performance evaluation,Performance metrics,Precision-recall curve},
  pages     = {67-77},
  publisher = {Springer Science and Business Media Deutschland GmbH},
  title     = {An Analysis of Performance Metrics for Imbalanced Classification},
  volume    = {12986 LNAI},
  url       = {https://link.springer.com/chapter/10.1007/978-3-030-88942-5_6},
  year      = {2021}
}

@article{Canbek2023,
  abstract  = {Although few performance evaluation instruments have been used conventionally in different machine learning-based classification problem domains, there are numerous ones defined in the literature. This study reviews and describes performance instruments via formally defined novel concepts and clarifies the terminology. The study first highlights the issues in performance evaluation via a survey of 78 mobile-malware classification studies and reviews terminology. Based on three research questions, it proposes novel concepts to identify characteristics, similarities, and differences of instruments that are categorized into ‘performance measures’ and ‘performance metrics’ in the classification context for the first time. The concepts reflecting the intrinsic properties of instruments such as canonical form, geometry, duality, complementation, dependency, and leveling, aim to reveal similarities and differences of numerous instruments, such as redundancy and ground-truth versus prediction focuses. As an application of knowledge representation, we introduced a new exploratory table called PToPI (Periodic Table of Performance Instruments) for 29 measures and 28 metrics (69 instruments including variant and parametric ones). Visualizing proposed concepts, PToPI provides a new relational structure for the instruments including graphical, probabilistic, and entropic ones to see their properties and dependencies all in one place. Applications of the exploratory table in six examples from different domains in the literature have shown that PToPI aids overall instrument analysis and selection of the proper performance metrics according to the specific requirements of a classification problem. We expect that the proposed concepts and PToPI will help researchers comprehend and use the instruments and follow a systematic approach to classification performance evaluation and publication.},
  author    = {Gürol Canbek and Tugba Taskaya Temizel and Seref Sagiroglu},
  doi       = {10.1007/S42979-022-01409-1/TABLES/2},
  issn      = {26618907},
  issue     = {1},
  journal   = {SN Computer Science},
  keywords  = {Classification,Knowledge representation,Machine learning,Performance evaluation,Performance measures,Performance metrics,Periodic table},
  month     = {1},
  pages     = {1-30},
  publisher = {Springer},
  title     = {PToPI: A Comprehensive Review, Analysis, and Knowledge Representation of Binary Classification Performance Measures/Metrics},
  volume    = {4},
  url       = {https://link.springer.com/article/10.1007/s42979-022-01409-1},
  year      = {2023}
}

@article{Ferri2009,
  abstract  = {Performance metrics in classification are fundamental in assessing the quality of learning methods and learned models. However, many different measures have been defined in the literature with the aim of making better choices in general or for a specific application area. Choices made by one metric are claimed to be different from choices made by other metrics. In this work, we analyse experimentally the behaviour of 18 different performance metrics in several scenarios, identifying clusters and relationships between measures. We also perform a sensitivity analysis for all of them in terms of several traits: class threshold choice, separability/ranking quality, calibration performance and sensitivity to changes in prior class distribution. From the definitions and experiments, we make a comprehensive analysis of the relationships between metrics, and a taxonomy and arrangement of them according to the previous traits. This can be useful for choosing the most adequate measure (or set of measures) for a specific application. Additionally, the study also highlights some niches in which new measures might be defined and also shows that some supposedly innovative measures make the same choices (or almost) as existing ones. Finally, this work can also be used as a reference for comparing experimental results in pattern recognition and machine learning literature, when using different measures.},
  author    = {C. Ferri and J. Hernández-Orallo and R. Modroiu},
  doi       = {10.1016/J.PATREC.2008.08.010},
  issn      = {0167-8655},
  issue     = {1},
  journal   = {Pattern Recognition Letters},
  month     = {1},
  pages     = {27-38},
  publisher = {North-Holland},
  title     = {An experimental comparison of performance measures for classification},
  volume    = {30},
  url       = {https://www.sciencedirect.com/science/article/abs/pii/S0167865508002687},
  year      = {2009}
}

@article{Seiffert2008,
  abstract = {Boosting has been shown to improve the performance of classifiers in many situations, including when data is im-balanced. There are, however, two possible implementations of boosting, and it is unclear which should be used. Boosting by reweighting is typically used, but can only be applied to base learners which are designed to handle example weights. On the other hand, boosting by resampling can be applied to any base learner. In this work, we empirically evaluate the differences between these two boosting implementations using imbalanced training data. Using 10 boosting algorithms, 4 learners and 15 datasets, we find that boosting by resampling performs as well as, or significantly better than, boosting by reweighting (which is often the default boosting implementation). We therefore conclude that in general, boosting by resampling is preferred over boosting by weighting. ©2008 IEEE.},
  author   = {Chris Seiffert and Taghi M. Khoshgoftaar and Jason Van Hulse and Amri Napolitano},
  doi      = {10.1109/ICTAI.2008.59},
  isbn     = {9780769534404},
  issn     = {10823409},
  journal  = {Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI},
  pages    = {445-451},
  title    = {Resampling or reweighting: A comparison of boosting implementations},
  volume   = {1},
  year     = {2008}
}

@article{Batuwita2010,
  abstract  = {Random undersampling and oversampling are simple but well-known resampling methods applied to solve the problem of class imbalance. In this paper we show that the random oversampling method can produce better classification results than the random undersampling method, since the oversampling can increase the minority class recognition rate by sacrificing less amount of majority class recognition rate than the undersampling method. However, the random oversampling method would increase the computational cost associated with the SVM training largely due to the addition of new training examples. In this paper we present an investigation carried out to develop efficient resampling methods that can produce comparable classification results to the random oversampling results, but with the use of less amount of data. The main idea of the proposed methods is to first select the most informative data examples located closer to the class boundary region by using the separating hyperplane found by training an SVM model on the original imbalanced dataset, and then use only those examples in resampling. We demonstrate that it would be possible to obtain comparable classification results to the random oversampling results through two sets of efficient resampling methods which use 50% less amount of data and 75% less amount of data, respectively, compared to the sizes of the datasets generated by the random oversampling method. © 2010 IEEE.},
  author    = {Rukshan Batuwita and Vasile Palade},
  doi       = {10.1109/IJCNN.2010.5596787},
  isbn      = {9781424469178},
  journal   = {Proceedings of the International Joint Conference on Neural Networks},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {Efficient resampling methods for training support vector machines with imbalanced datasets},
  year      = {2010}
}

@article{Namvar2018,
  abstract  = {Credit risk prediction is an effective way of evaluating whether a potential borrower will repay a loan, particularly in peer-to-peer lending where class imbalance problems are prevalent. However, few credit risk prediction models for social lending consider imbalanced data and, further, the best resampling technique to use with imbalanced data is still controversial. In an attempt to address these problems, this paper presents an empirical comparison of various combinations of classifiers and resampling techniques within a novel risk assessment methodology that incorporates imbalanced data. The credit predictions from each combination are evaluated with a G-mean measure to avoid bias towards the majority class, which has not been considered in similar studies. The results reveal that combining random forest and random under-sampling may be an effective strategy for calculating the credit risk associated with loan applicants in social lending markets.},
  author    = {Anahita Namvar and Mohammad Siami and Fethi Rabhi and Mohsen Naderpour},
  doi       = {10.2991/IJCIS.11.1.70/METRICS},
  issn      = {18756883},
  issue     = {1},
  journal   = {International Journal of Computational Intelligence Systems},
  keywords  = {Imbalance classification,Peer-to-peer lending,Resampling,Risk prediction},
  month     = {3},
  pages     = {925-935},
  publisher = {Atlantis Press},
  title     = {Credit risk prediction in an imbalanced social lending environment},
  volume    = {11},
  url       = {https://link-springer-com.ez42.periodicos.capes.gov.br/article/10.2991/ijcis.11.1.70},
  year      = {2018}
}

@article{Chakravarthy2019,
  abstract  = {Class imbalance is a problem of crucial challenge in many real-world machine learning applications. Traditional machine learning algorithms are likely to produce good accuracy scores on such datasets due to an obvious bias towards the majority class. Thus, accuracy as a measure of performance for algorithms working on imbalanced data is not very clearly defined since the classifier has poor predictive accuracy over the minority class. While previous work has used several resampling techniques to aid in improving the predictive accuracy of the minority class, in this study, we explore and compare the effectiveness of the Synthetic Minority Oversampling and Random Oversampling techniques over multiple learning algorithms and resampling ratios for eight different performance measures against two datasets from diverse domains such as medicine and engineering. The results of this study show that the effectiveness of these resampling techniques is a multivariate function relative to both the learning algorithms and the resampling ratios, as well as the coherent characteristics of datasets. The choice of performance measures to evaluate models built using these resampling techniques also vary, thus giving us more relevant information useful for future research and applications.},
  author    = {Adithi D. Chakravarthy and Sindhura Bonthu and Zhengxin Chen and Qiuming Zhu},
  doi       = {10.1109/ICMLA.2019.00245},
  isbn      = {9781728145495},
  journal   = {Proceedings - 18th IEEE International Conference on Machine Learning and Applications, ICMLA 2019},
  keywords  = {Class-imbalance,Classification,Oversampling,Predictive-models,Resampling,Undersampling},
  month     = {12},
  pages     = {1492-1495},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {Predictive models with resampling: A comparative study of machine learning algorithms and their performances on handling imbalanced datasets},
  year      = {2019}
}

@article{Carvalho2025,
  abstract  = {This article presents a data-driven review of resampling approaches aimed at mitigating the class imbalance problem in machine learning, a widespread issue that limits classifier performance across numerous sectors. Initially, this research provides an extensive theoretical examination of the class imbalance problem, emphasizing its propensity to amplify existing data difficulty factors, including class overlap, small disjuncts, and noise, thus biasing the model towards the majority class. Acknowledging the significance of detecting and quantifying the synergistic effects between class imbalance and these data difficulty factors, this study surveys metrics formulated to quantify such phenomena in imbalanced domains. Subsequently, an exhaustive review of recent oversampling, undersampling, and hybrid sampling approaches is conducted. A major finding arising from this review is the discernible shift in resampling approaches towards enhanced adaptability. This is achieved through the identification of problematic regions and the subsequent implementation of customized resampling protocols. Concurrently, a methodological divergence is observed in both oversampling and undersampling strategies: certain oversampling methods target regions of higher classification complexity, which are crucial for effective model training, while others focus on areas of lower classification complexity to safely oversample the minority class. In contrast, undersampling approaches either predominantly remove majority samples from redundant regions or focus on class boundaries to reduce class overlap. However, despite this increased adaptability, no resampling method consistently demonstrated superior performance across all documented experiments. Consequently, we explore a promising strategy, namely the adoption of recommendation systems for resampling approaches. Lastly, the primary research challenges within this topic are discussed.},
  author    = {Miguel Carvalho and Armando J. Pinho and Susana Brás},
  doi       = {10.1186/S40537-025-01119-4},
  issn      = {2196-1115},
  issue     = {1},
  journal   = {Journal of Big Data 2025 12:1},
  keywords  = {Communications Engineering,Computational Science and Engineering,Data Mining and Knowledge Discovery,Database Management,Information Storage and Retrieval,Mathematical Applications in Computer Science,Networks,Resampling approaches,SMOTE},
  month     = {3},
  pages     = {1-58},
  publisher = {SpringerOpen},
  title     = {Resampling approaches to handle class imbalance: a review from a data perspective},
  volume    = {12},
  url       = {https://link-springer-com.ez42.periodicos.capes.gov.br/articles/10.1186/s40537-025-01119-4 https://link-springer-com.ez42.periodicos.capes.gov.br/article/10.1186/s40537-025-01119-4},
  year      = {2025}
}

@article{Haixiang2017,
  abstract  = {Rare events, especially those that could potentially negatively impact society, often require humans’ decision-making responses. Detecting rare events can be viewed as a prediction task in data mining and machine learning communities. As these events are rarely observed in daily life, the prediction task suffers from a lack of balanced data. In this paper, we provide an in depth review of rare event detection from an imbalanced learning perspective. Five hundred and seventeen related papers that have been published in the past decade were collected for the study. The initial statistics suggested that rare events detection and imbalanced learning are concerned across a wide range of research areas from management science to engineering. We reviewed all collected papers from both a technical and a practical point of view. Modeling methods discussed include techniques such as data preprocessing, classification algorithms and model evaluation. For applications, we first provide a comprehensive taxonomy of the existing application domains of imbalanced learning, and then we detail the applications for each category. Finally, some suggestions from the reviewed papers are incorporated with our experiences and judgments to offer further research directions for the imbalanced learning and rare event detection fields.},
  author    = {Guo Haixiang and Li Yijing and Jennifer Shang and Gu Mingyun and Huang Yuanyue and Gong Bing},
  doi       = {10.1016/J.ESWA.2016.12.035},
  issn      = {0957-4174},
  journal   = {Expert Systems with Applications},
  keywords  = {Data mining,Imbalanced data,Machine learning,Rare events},
  month     = {5},
  pages     = {220-239},
  publisher = {Pergamon},
  title     = {Learning from class-imbalanced data: Review of methods and applications},
  volume    = {73},
  url       = {https://www-sciencedirect-com.ez42.periodicos.capes.gov.br/science/article/pii/S0957417416307175},
  year      = {2017}
}

@article{Mohammed2020,
  abstract  = {Data imbalance in Machine Learning refers to an unequal distribution of classes within a dataset. This issue is encountered mostly in classification tasks in which the distribution of classes or labels in a given dataset is not uniform. The straightforward method to solve this problem is the resampling method by adding records to the minority class or deleting ones from the majority class. In this paper, we have experimented with the two resampling widely adopted techniques: oversampling and undersampling. In order to explore both techniques, we have chosen a public imbalanced dataset from kaggle website Santander Customer Transaction Prediction and have applied a group of well-known machine learning algorithms with different hyperparamters that give best results for both resampling techniques. One of the key findings of this paper is noticing that oversampling performs better than undersampling for different classifiers and obtains higher scores in different evaluation metrics.},
  author    = {Roweida Mohammed and Jumanah Rawashdeh and Malak Abdullah},
  doi       = {10.1109/ICICS49469.2020.239556},
  isbn      = {9781728162270},
  journal   = {2020 11th International Conference on Information and Communication Systems, ICICS 2020},
  keywords  = {Accuracy,Class Imbalance,Machine Learning,Naive Bayes,Oversampling,Precision,Random Forest,Recall,SVM,Undersampling},
  month     = {4},
  pages     = {243-248},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {Machine Learning with Oversampling and Undersampling Techniques: Overview Study and Experimental Results},
  year      = {2020}
}

@article{Yang2024,
  abstract  = {Background: There is currently no consensus on the impact of class imbalance methods on the performance of clinical prediction models. We aimed to empirically investigate the impact of random oversampling and random undersampling, two commonly used class imbalance methods, on the internal and external validation performance of prediction models developed using observational health data. Methods: We developed and externally validated prediction models for various outcomes of interest within a target population of people with pharmaceutically treated depression across four large observational health databases. We used three different classifiers (lasso logistic regression, random forest, XGBoost) and varied the target imbalance ratio. We evaluated the impact on model performance in terms of discrimination and calibration. Discrimination was assessed using the area under the receiver operating characteristic curve (AUROC) and calibration was assessed using calibration plots. Results: We developed and externally validated a total of 1,566 prediction models. On internal and external validation, random oversampling and random undersampling generally did not result in higher AUROCs. Moreover, we found overestimated risks, although this miscalibration could largely be corrected by recalibrating the models towards the imbalance ratios in the original dataset. Conclusions: Overall, we found that random oversampling or random undersampling generally does not improve the internal and external validation performance of prediction models developed in large observational health databases. Based on our findings, we do not recommend applying random oversampling or random undersampling when developing prediction models in large observational health databases.},
  author    = {Cynthia Yang and Egill A. Fridgeirsson and Jan A. Kors and Jenna M. Reps and Peter R. Rijnbeek},
  doi       = {10.1186/S40537-023-00857-7/FIGURES/6},
  issn      = {21961115},
  issue     = {1},
  journal   = {Journal of Big Data},
  keywords  = {Class Imbalance Problem,Clinical decision support,Clinical prediction model,External validation,Machine learning,Patient-level prediction},
  month     = {12},
  pages     = {1-17},
  publisher = {Springer Nature},
  title     = {Impact of random oversampling and random undersampling on the performance of prediction models developed using observational health data},
  volume    = {11},
  url       = {https://link.springer.com/articles/10.1186/s40537-023-00857-7 https://link.springer.com/article/10.1186/s40537-023-00857-7},
  year      = {2024}
}

@article{Fernndez2018,
  abstract  = {The Synthetic Minority Oversampling Technique (SMOTE) preprocessing algorithm is considered "de facto" standard in the framework of learning from imbalanced data. This is due to its simplicity in the design of the procedure, as well as its robustness when applied to different type of problems. Since its publication in 2002, SMOTE has proven successful in a variety of applications from several different domains. SMOTE has also inspired several approaches to counter the issue of class imbalance, and has also significantly contributed to new supervised learning paradigms, including multilabel classification, incremental learning, semi-supervised learning, multi-instance learning, among others. It is standard benchmark for learning from imbalanced data. It is also featured in a number of different software packages - from open source to commercial. In this paper, marking the fifteen year anniversary of SMOTE, we reflect on the SMOTE journey, discuss the current state of affairs with SMOTE, its applications, and also identify the next set of challenges to extend SMOTE for Big Data problems.},
  author    = {Alberto Fernández and Salvador García and Francisco Herrera and Nitesh V. Chawla},
  doi       = {10.1613/JAIR.1.11192},
  issn      = {1076-9757},
  journal   = {Journal of Artificial Intelligence Research},
  month     = {4},
  pages     = {863-905},
  publisher = {AI Access Foundation},
  title     = {SMOTE for Learning from Imbalanced Data: Progress and Challenges, Marking the 15-year Anniversary},
  volume    = {61},
  url       = {https://www.jair.org/index.php/jair/article/view/11192},
  year      = {2018}
}

@article{Chawla2002,
  abstract  = {An approach to the construction of classifiers from    imbalanced datasets is described. A dataset is imbalanced if the    classification categories are not approximately equally    represented. Often real-world data sets are predominately composed of    ``normal'' examples with only a small percentage of ``abnormal'' or    ``interesting'' examples. It is also the case that the cost of    misclassifying an abnormal (interesting) example as a normal example    is often much higher than the cost of the reverse    error. Under-sampling of the majority (normal) class has been proposed    as a good means of increasing the sensitivity of a classifier to the    minority class. This paper shows that a combination of our method of    over-sampling the minority (abnormal) class and under-sampling the    majority (normal) class can achieve better classifier performance (in    ROC space) than only under-sampling the majority class.  This paper    also shows that a combination of our method of over-sampling the    minority class and under-sampling the majority class can achieve    better classifier performance (in ROC space) than varying the loss    ratios in Ripper or class priors in Naive Bayes. Our method of    over-sampling the minority class involves creating synthetic minority    class examples.  Experiments are performed using C4.5, Ripper and a    Naive Bayes classifier. The method is evaluated using the area under    the Receiver Operating Characteristic curve (AUC) and the ROC convex    hull strategy.},
  author    = {Nitesh V. Chawla and Kevin W. Bowyer and Lawrence O. Hall and W. Philip Kegelmeyer},
  doi       = {10.1613/JAIR.953},
  issn      = {1076-9757},
  journal   = {Journal of Artificial Intelligence Research},
  month     = {6},
  pages     = {321-357},
  publisher = {American Association for Artificial Intelligence},
  title     = {SMOTE: Synthetic Minority Over-sampling Technique},
  volume    = {16},
  url       = {https://www.jair.org/index.php/jair/article/view/10302},
  year      = {2002}
}

@article{Wei2025,
  abstract  = {Against the backdrop of dynamic transformations in the financial sector and prominent corporate diversification trends, credit risk prediction becomes significantly more challenging. On one hand, this study focuses on optimizing the Synthetic Minority Over-Sampling Technique (SMOTE) algorithm for corporate credit risk prediction, thereby enhancing financial institutions’ risk management capabilities. The study systematically examines corporate diversification strategies, revealing discrepancies between theoretical frameworks and practical implementations. These strategies complicate corporate financial structures, generating divergent profitability, capital allocation, and risk profiles across business units. Such heterogeneity leads to uneven resource distribution, ultimately impacting enterprise operations, debt servicing capacity, and credit performance. Consequently, financial institutions increasingly prioritize cross-sectoral risk monitoring, business synergy evaluation, and dynamic financial tracking. On the other hand, regarding algorithmic innovation, this study conducts an in-depth analysis of SMOTE’s fundamental principles, encompassing its sample generation mechanics and optimized variants. Especially in terms of optimization content, this study innovatively introduces an adaptive boundary adjustment mechanism that automatically defines minority class boundaries based on data distribution characteristics. Meanwhile, it precisely targets critical oversampling areas while avoiding arbitrary sample generation in irrelevant regions. Moreover, an optimized weight allocation protocol during synthetic sample creation incorporates feature relevance and class distribution to produce more representative new samples. The experimental framework utilizes four benchmark datasets: German Credit, Australian Credit Approval, Taiwan Credit Card Default, and Corporate Credit Risk Assessment. The rigorous methodology ensures research validity through scientific data partitioning, appropriate hardware configuration, an advanced software environment, and comprehensive evaluation indices (accuracy, precision, recall, F1-score). The study mainly focuses on two aspects. One is to analyze corporate diversification strategy; the other is to explore the optimization of the SMOTE algorithm and its application in credit risk prediction. Empirical results demonstrate the optimized SMOTE algorithm’s superiority over six comparison models, such as random over-sampling, under-sampling, etc. The accuracy rate is improved by more than 21%, and the highest is close to 38%. Precision is enhanced by over 28%, peak nearly 35%; Recall is increased by more than 31% and peaked at 42%; F1 score is boosted by approximately 33%, with a maximum of about 39%. This study provides financial institutions with an advanced algorithmic solution for credit risk assessment in diversified corporate environments. Also, it is expected to improve decision-making accuracy, strengthen risk resilience, and promote financial market stability.},
  author    = {Han Wei},
  doi       = {10.1038/S41598-025-09173-X;SUBJMETA=1041,1042,531,639,705;KWRD=APPLIED+MATHEMATICS,COMPUTATIONAL+SCIENCE,STATISTICS},
  issn      = {20452322},
  issue     = {1},
  journal   = {Scientific Reports},
  keywords  = {Corporate diversification,Credit risk,Financial sector,Risk monitoring,SMOTE algorithm},
  month     = {12},
  pages     = {1-18},
  publisher = {Nature Research},
  title     = {SMOTE algorithm optimization and application in corporate credit risk prediction with diversification strategy consideration},
  volume    = {15},
  url       = {https://www-nature-com.ez42.periodicos.capes.gov.br/articles/s41598-025-09173-x},
  year      = {2025}
}

@article{Batista2004,
  abstract  = {There are several aspects that might influence the performance achieved by existing learning systems. It has been reported that one of these aspects is related to class imbalance in which examples ...},
  author    = {Gustavo E. A. P. A. Batista and Ronaldo C. Prati and Maria Carolina Monard},
  doi       = {10.1145/1007730.1007735},
  issn      = {1931-0145},
  issue     = {1},
  journal   = {ACM SIGKDD Explorations Newsletter},
  month     = {6},
  pages     = {20-29},
  publisher = {ACMPUB27New York, NY, USA},
  title     = {A study of the behavior of several methods for balancing machine learning training data},
  volume    = {6},
  url       = {/doi/pdf/10.1145/1007730.1007735?download=true},
  year      = {2004}
}

@misc{Arichandrapandian2024,
  author = {Thangaselvi Arichandrapandian},
  month  = {5},
  title  = {Upsampling And Downsampling: Correcting The Imbalances In Data - Open Source For You},
  url    = {https://www.opensourceforu.com/2024/05/upsampling-and-downsampling-correcting-the-imbalances-in-data-2/},
  year   = {2024}
}

@article{Pereira2020,
  abstract  = {A large variety of problems are multi-labeled, which made the Multi-Label Classification field become an active topic in the machine learning community. However, real world problems tend to be imbalanced, meaning that some classes may have more samples than others. Learning from imbalanced datasets is a challenging task and for that has attracted the attention of researchers that have proposed some resampling algorithms to address this problem. This work presents two main contributions: A new resampling algorithm for multi-label classification problems named MLTL - Multi-Label Tomek Link, which is based on the standard Tomek Link resampling algorithm; A multi-label imbalanceness API for the Mulan framework. Results in seven well-known datasets showed that MLTL is a competitive technique when compared to other multi-label resampling methods from the literature.},
  author    = {Rodolfo M. Pereira and Yandre M.G. Costa and Carlos N. Silla},
  doi       = {10.1016/J.NEUCOM.2019.11.076},
  issn      = {0925-2312},
  journal   = {Neurocomputing},
  keywords  = {Dataset imbalanceness,Multi-label learning,Resampling techniques},
  month     = {3},
  pages     = {95-105},
  publisher = {Elsevier},
  title     = {MLTL: A multi-label approach for the Tomek Link undersampling algorithm},
  volume    = {383},
  url       = {https://www.sciencedirect.com/science/article/abs/pii/S0925231219316790},
  year      = {2020}
}

@article{He2008,
  abstract = {This paper presents a novel adaptive synthetic (ADASYN) sampling approach for learning from imbalanced data sets. The essential idea of ADASYN is to use a weighted distribution for different minority class examples according to their level of difficulty in learning, where more synthetic data is generated for minority class examples that are harder to learn compared to those minority examples that are easier to learn. As a result, the ADASYN approach improves learning with respect to the data distributions in two ways: (1) reducing the bias introduced by the class imbalance, and (2) adaptively shifting the classification decision boundary toward the difficult examples. Simulation analyses on several machine learning data sets show the effectiveness of this method across five evaluation metrics. ©2008 IEEE.},
  author   = {Haibo He and Yang Bai and Edwardo A. Garcia and Shutao Li},
  doi      = {10.1109/IJCNN.2008.4633969},
  isbn     = {9781424418213},
  journal  = {Proceedings of the International Joint Conference on Neural Networks},
  pages    = {1322-1328},
  title    = {ADASYN: Adaptive synthetic sampling approach for imbalanced learning},
  year     = {2008}
}

@article{FernndezCs2018,
  abstract  = {Cost-sensitive learning is an aspect of algorithm-level modifications for class imbalance. Here, instead of using a standard error-driven evaluation (or 0–1 loss function), a misclassification cost is being introduced in order to minimize the conditional risk....},
  author    = {Alberto Fernández and Salvador García and Mikel Galar and Ronaldo C. Prati and Bartosz Krawczyk and Francisco Herrera},
  doi       = {10.1007/978-3-319-98074-4_4},
  isbn      = {978-3-319-98074-4},
  journal   = {Learning from Imbalanced Data Sets},
  pages     = {63-78},
  publisher = {Springer, Cham},
  title     = {Cost-Sensitive Learning},
  url       = {https://link-springer-com.ez42.periodicos.capes.gov.br/chapter/10.1007/978-3-319-98074-4_4},
  year      = {2018}
}
